{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb36e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Model, save_model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('F:/2025-PROJECTS/fake_news/dataset/fake_news_dataset.csv')\n",
    "\n",
    "# Combine title and content for better context\n",
    "df['text'] = df['Article Title'] + ' ' + df['Content']\n",
    "X = df['text']\n",
    "y = df['Label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 200\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Component 1: News Characterizer (CNN)\n",
    "def build_news_characterizer():\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=128)(input_layer)\n",
    "    conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding)\n",
    "    pool1 = GlobalMaxPooling1D()(conv1)\n",
    "    conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(embedding)\n",
    "    pool2 = GlobalMaxPooling1D()(conv2)\n",
    "    merged = concatenate([pool1, pool2])\n",
    "    output = Dense(64, activation='relu')(merged)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Component 2: Ensemble Coordinator\n",
    "def build_ensemble_coordinator(input_shape):\n",
    "    input_layer = Input(shape=(input_shape,))\n",
    "    dense1 = Dense(64, activation='relu')(input_layer)\n",
    "    dense2 = Dense(32, activation='relu')(dense1)\n",
    "    output = Dense(1, activation='sigmoid')(dense2)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Component 3: Truth Predictor (using ensemble of traditional models)\n",
    "class TruthPredictor:\n",
    "    def __init__(self):\n",
    "        self.models = [\n",
    "            RandomForestClassifier(n_estimators=100),\n",
    "            SVC(probability=True)\n",
    "        ]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict_proba(X)[:, 1]\n",
    "            predictions.append(pred)\n",
    "        return np.mean(predictions, axis=0)\n",
    "\n",
    "# Build and train CKA model\n",
    "news_characterizer = build_news_characterizer()\n",
    "ensemble_coordinator = build_ensemble_coordinator(128)  # 64*2 from CNN outputs\n",
    "\n",
    "# Extract features from News Characterizer\n",
    "X_train_features = news_characterizer.predict(X_train_pad)\n",
    "X_test_features = news_characterizer.predict(X_test_pad)\n",
    "\n",
    "# Train Ensemble Coordinator\n",
    "ensemble_coordinator.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "ensemble_coordinator.fit(X_train_features, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Train Truth Predictor\n",
    "truth_predictor = TruthPredictor()\n",
    "truth_predictor.fit(X_train_features, y_train)\n",
    "\n",
    "# Make predictions\n",
    "coordinator_preds = (ensemble_coordinator.predict(X_test_features) > 0.5).astype(int).flatten()\n",
    "truth_preds = (truth_predictor.predict(X_test_features) > 0.5).astype(int)\n",
    "\n",
    "# Combine predictions (simple average for demonstration)\n",
    "final_preds = np.round((coordinator_preds + truth_preds) / 2).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, final_preds)\n",
    "precision = precision_score(y_test, final_preds)\n",
    "recall = recall_score(y_test, final_preds)\n",
    "f1 = f1_score(y_test, final_preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Save all model components\n",
    "save_model(news_characterizer, 'news_characterizer.h5')\n",
    "save_model(ensemble_coordinator, 'ensemble_coordinator.h5')\n",
    "\n",
    "with open('truth_predictor.pkl', 'wb') as f:\n",
    "    pickle.dump(truth_predictor, f)\n",
    "\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "model_metadata = {\n",
    "    'max_words': max_words,\n",
    "    'max_len': max_len\n",
    "}\n",
    "with open('model_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(model_metadata, f)\n",
    "\n",
    "print(\"All model components saved successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080f5bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 31ms/step\n",
      "7/7 [==============================] - 0s 28ms/step\n",
      "Epoch 1/10\n",
      "23/23 [==============================] - 2s 19ms/step - loss: 0.6879 - accuracy: 0.5250 - val_loss: 0.6811 - val_accuracy: 0.5250\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.6711 - accuracy: 0.5847 - val_loss: 0.6581 - val_accuracy: 0.8500\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.6264 - accuracy: 0.8125 - val_loss: 0.5909 - val_accuracy: 0.9000\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 0s 7ms/step - loss: 0.5311 - accuracy: 0.8889 - val_loss: 0.4810 - val_accuracy: 0.8375\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 0s 9ms/step - loss: 0.4038 - accuracy: 0.9361 - val_loss: 0.3439 - val_accuracy: 0.9625\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.2713 - accuracy: 0.9681 - val_loss: 0.2393 - val_accuracy: 0.9625\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1807 - accuracy: 0.9861 - val_loss: 0.1682 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.1257 - accuracy: 0.9958 - val_loss: 0.1053 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0812 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 0s 8ms/step - loss: 0.0569 - accuracy: 1.0000 - val_loss: 0.0533 - val_accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 6ms/step\n",
      "\n",
      "Final Model Performance:\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1 Score: 1.0000\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tech\\AppData\\Local\\Temp\\ipykernel_13072\\1389080049.py:121: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(news_characterizer, 'news_characterizer.h5')\n",
      "C:\\Users\\tech\\AppData\\Local\\Temp\\ipykernel_13072\\1389080049.py:122: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  save_model(ensemble_coordinator, 'ensemble_coordinator.h5')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All model components saved successfully:\n",
      "- news_characterizers.h5\n",
      "- ensemble_coordinators.h5\n",
      "- truth_predictors.pkl\n",
      "- tokenizers.pkl\n",
      "- model_metadatas.pkl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Model, save_model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, concatenate\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('F:/2025-PROJECTS/fake_news/dataset/fake_news_dataset.csv')\n",
    "\n",
    "# Combine title and content for better context\n",
    "df['text'] = df['Article Title'] + ' ' + df['Content']\n",
    "X = df['text']\n",
    "y = df['Label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 200\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Component 1: News Characterizer (CNN)\n",
    "def build_news_characterizer():\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=128)(input_layer)\n",
    "    conv1 = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding)\n",
    "    pool1 = GlobalMaxPooling1D()(conv1)\n",
    "    conv2 = Conv1D(filters=64, kernel_size=5, activation='relu')(embedding)\n",
    "    pool2 = GlobalMaxPooling1D()(conv2)\n",
    "    conv3 = Conv1D(filters=64, kernel_size=7, activation='relu')(embedding)\n",
    "    pool3 = GlobalMaxPooling1D()(conv3)\n",
    "    merged = concatenate([pool1, pool2, pool3])\n",
    "    output = Dense(128, activation='relu')(merged)  # Increased to 128 to match expected input\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Component 2: Ensemble Coordinator\n",
    "def build_ensemble_coordinator(input_shape):\n",
    "    input_layer = Input(shape=(input_shape,))\n",
    "    dense1 = Dense(128, activation='relu')(input_layer)  # Match the input shape\n",
    "    dense2 = Dense(64, activation='relu')(dense1)\n",
    "    output = Dense(1, activation='sigmoid')(dense2)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Component 3: Truth Predictor (using ensemble of traditional models)\n",
    "class TruthPredictor:\n",
    "    def __init__(self):\n",
    "        self.models = [\n",
    "            RandomForestClassifier(n_estimators=100),\n",
    "            SVC(probability=True)\n",
    "        ]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        for model in self.models:\n",
    "            model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for model in self.models:\n",
    "            pred = model.predict_proba(X)[:, 1]\n",
    "            predictions.append(pred)\n",
    "        return np.mean(predictions, axis=0)\n",
    "\n",
    "# Build and train CKA model\n",
    "news_characterizer = build_news_characterizer()\n",
    "ensemble_coordinator = build_ensemble_coordinator(128)  # Matches News Characterizer output\n",
    "\n",
    "# Extract features from News Characterizer\n",
    "X_train_features = news_characterizer.predict(X_train_pad)\n",
    "X_test_features = news_characterizer.predict(X_test_pad)\n",
    "\n",
    "# Train Ensemble Coordinator\n",
    "ensemble_coordinator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = ensemble_coordinator.fit(\n",
    "    X_train_features, \n",
    "    y_train, \n",
    "    epochs=10, \n",
    "    batch_size=32, \n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train Truth Predictor\n",
    "truth_predictor = TruthPredictor()\n",
    "truth_predictor.fit(X_train_features, y_train)\n",
    "\n",
    "# Make predictions\n",
    "coordinator_preds = (ensemble_coordinator.predict(X_test_features) > 0.5).astype(int).flatten()\n",
    "truth_preds = (truth_predictor.predict(X_test_features) > 0.5).astype(int)\n",
    "\n",
    "# Combine predictions (simple average for demonstration)\n",
    "final_preds = np.round((coordinator_preds + truth_preds) / 2).astype(int)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, final_preds)\n",
    "precision = precision_score(y_test, final_preds)\n",
    "recall = recall_score(y_test, final_preds)\n",
    "f1 = f1_score(y_test, final_preds)\n",
    "\n",
    "print(\"\\nFinal Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Save all model components\n",
    "save_model(news_characterizer, 'news_characterizer.h5')\n",
    "save_model(ensemble_coordinator, 'ensemble_coordinator.h5')\n",
    "\n",
    "with open('truth_predictor.pkl', 'wb') as f:\n",
    "    pickle.dump(truth_predictor, f)\n",
    "\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "model_metadata = {\n",
    "    'max_words': max_words,\n",
    "    'max_len': max_len\n",
    "}\n",
    "with open('model_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(model_metadata, f)\n",
    "\n",
    "print(\"\\nAll model components saved successfully:\")\n",
    "print(\"- news_characterizers.h5\")\n",
    "print(\"- ensemble_coordinators.h5\")\n",
    "print(\"- truth_predictors.pkl\")\n",
    "print(\"- tokenizers.pkl\")\n",
    "print(\"- model_metadatas.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef1ff16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Detection Results:\n",
      "--------------------------------------------------\n",
      "WARNING:tensorflow:5 out of the last 40 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F24D506840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 40 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F24D506840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 41 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F24D507420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 41 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F24D507420> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Breaking News: Market Crash, Experts discuss the implication...\n",
      "Prediction: Real\n",
      "Confidence: 99.14%\n",
      "Coordinator Score: 0.9846\n",
      "Truth Predictor Score: 0.9981\n",
      "--------------------------------------------------\n",
      "Text: Political Scandal Unveiled, Clickbait! No credible sources s...\n",
      "Prediction: Fake\n",
      "Confidence: 99.10%\n",
      "Coordinator Score: 0.0160\n",
      "Truth Predictor Score: 0.0020\n",
      "--------------------------------------------------\n",
      "Text: Tech Company Launches New Product, Details from a press conf...\n",
      "Prediction: Real\n",
      "Confidence: 99.52%\n",
      "Coordinator Score: 0.9904\n",
      "Truth Predictor Score: 1.0000\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "class CKAPredictor:\n",
    "    def __init__(self, model_dir='./'):\n",
    "        \"\"\"Initialize and load all model components\"\"\"\n",
    "        # Load all saved components\n",
    "        self.news_characterizer = load_model(f'{model_dir}news_characterizer.h5')\n",
    "        self.ensemble_coordinator = load_model(f'{model_dir}ensemble_coordinator.h5')\n",
    "        \n",
    "        with open(f'{model_dir}truth_predictor.pkl', 'rb') as f:\n",
    "            self.truth_predictor = pickle.load(f)\n",
    "            \n",
    "        with open(f'{model_dir}tokenizer.pkl', 'rb') as f:\n",
    "            self.tokenizer = pickle.load(f)\n",
    "            \n",
    "        with open(f'{model_dir}model_metadata.pkl', 'rb') as f:\n",
    "            self.metadata = pickle.load(f)\n",
    "    \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Convert raw text to padded sequence\"\"\"\n",
    "        seq = self.tokenizer.texts_to_sequences([text])\n",
    "        return pad_sequences(seq, maxlen=self.metadata['max_len'])\n",
    "    \n",
    "    def predict(self, text, return_proba=False):\n",
    "        \"\"\"\n",
    "        Make prediction on new text\n",
    "        Args:\n",
    "            text: str - the news text to classify\n",
    "            return_proba: bool - whether to return probability scores\n",
    "        Returns:\n",
    "            dict with prediction and probabilities\n",
    "        \"\"\"\n",
    "        # Preprocess text\n",
    "        padded_seq = self.preprocess_text(text)\n",
    "        \n",
    "        # Get features from News Characterizer\n",
    "        features = self.news_characterizer.predict(padded_seq, verbose=0)\n",
    "        \n",
    "        # Get predictions from both components\n",
    "        coord_pred = self.ensemble_coordinator.predict(features, verbose=0)[0][0]\n",
    "        truth_pred = self.truth_predictor.predict(features)[0]\n",
    "        \n",
    "        # Combine predictions (average)\n",
    "        combined_pred = (coord_pred + truth_pred) / 2\n",
    "        final_pred = int(combined_pred > 0.5)\n",
    "        \n",
    "        # Prepare results\n",
    "        result = {\n",
    "            'prediction': 'Real' if final_pred == 1 else 'Fake',\n",
    "            'confidence': float(combined_pred if final_pred == 1 else 1 - combined_pred),\n",
    "            'coordinator_score': float(coord_pred),\n",
    "            'truth_predictor_score': float(truth_pred)\n",
    "        }\n",
    "        \n",
    "        return result if not return_proba else {**result, 'combined_probability': float(combined_pred)}\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize predictor (assuming models are in current directory)\n",
    "    predictor = CKAPredictor()\n",
    "    \n",
    "    # Sample news texts\n",
    "    test_texts = [\n",
    "        \"Breaking News: Market Crash, Experts discuss the implications of the new product\",\n",
    "        \"Political Scandal Unveiled, Clickbait! No credible sources support this claim\",\n",
    "        \"Tech Company Launches New Product, Details from a press conference held earlier\"\n",
    "    ]\n",
    "    \n",
    "    # Make predictions\n",
    "    print(\"Fake News Detection Results:\\n\" + \"-\"*50)\n",
    "    for text in test_texts:\n",
    "        result = predictor.predict(text)\n",
    "        print(f\"Text: {text[:60]}...\")\n",
    "        print(f\"Prediction: {result['prediction']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "        print(f\"Coordinator Score: {result['coordinator_score']:.4f}\")\n",
    "        print(f\"Truth Predictor Score: {result['truth_predictor_score']:.4f}\")\n",
    "        print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dc465eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Detection Result:\n",
      "==================================================\n",
      "News Snippet: Government Announces New Policies, Details from a press conference held earlier\n",
      "Prediction: REAL\n",
      "Confidence: 99.7%\n",
      "\n",
      "Detailed Scores:\n",
      "- Ensemble Coordinator: 0.9931\n",
      "- Truth Predictor: 1.0000\n",
      "- Combined Score: 0.9966\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load all model components\n",
    "news_characterizer = load_model('news_characterizer.h5')\n",
    "ensemble_coordinator = load_model('ensemble_coordinator.h5')\n",
    "\n",
    "with open('truth_predictor.pkl', 'rb') as f:\n",
    "    truth_predictor = pickle.load(f)\n",
    "    \n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "    \n",
    "with open('model_metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "def predict_news(text):\n",
    "    \"\"\"Predict if a single news article is real or fake\"\"\"\n",
    "    # Preprocess the text\n",
    "    seq = tokenizer.texts_to_sequences([text])\n",
    "    padded = pad_sequences(seq, maxlen=metadata['max_len'])\n",
    "    \n",
    "    # Get features from News Characterizer\n",
    "    features = news_characterizer.predict(padded, verbose=0)\n",
    "    \n",
    "    # Get predictions from both components\n",
    "    coord_score = ensemble_coordinator.predict(features, verbose=0)[0][0]\n",
    "    truth_score = truth_predictor.predict(features)[0]\n",
    "    \n",
    "    # Combine predictions (average)\n",
    "    combined_score = (coord_score + truth_score) / 2\n",
    "    is_real = combined_score > 0.5\n",
    "    \n",
    "    return {\n",
    "        'text': text[:100] + '...' if len(text) > 100 else text,\n",
    "        'prediction': 'REAL' if is_real else 'FAKE',\n",
    "        'confidence': f\"{max(combined_score, 1-combined_score)*100:.1f}%\",\n",
    "        'coordinator_score': f\"{coord_score:.4f}\",\n",
    "        'truth_predictor_score': f\"{truth_score:.4f}\",\n",
    "        'combined_score': f\"{combined_score:.4f}\"\n",
    "    }\n",
    "\n",
    "# Example usage with one news article\n",
    "sample_news = \"Government Announces New Policies, Details from a press conference held earlier\"\n",
    "result = predict_news(sample_news)\n",
    "\n",
    "# Print the results\n",
    "print(\"Fake News Detection Result:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"News Snippet: {result['text']}\")\n",
    "print(f\"Prediction: {result['prediction']}\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n",
    "print(\"\\nDetailed Scores:\")\n",
    "print(f\"- Ensemble Coordinator: {result['coordinator_score']}\")\n",
    "print(f\"- Truth Predictor: {result['truth_predictor_score']}\")\n",
    "print(f\"- Combined Score: {result['combined_score']}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c62b03a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Detection Analysis:\n",
      "======================================================================\n",
      "Title: Tech Company Launches New Product\n",
      "Content: Clickbait! No credible sources support this claim.\n",
      "\n",
      "Prediction Results:\n",
      "- Model Prediction: FAKE (Actual: FAKE)\n",
      "- Confidence: 98.8%\n",
      "\n",
      "Component Scores:\n",
      "- Ensemble Coordinator: 0.0230\n",
      "- Truth Predictor: 0.0020\n",
      "- Combined Decision Score: 0.0125\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Prediction MATCHES the actual label!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load all model components\n",
    "news_characterizer = load_model('news_characterizer.h5')\n",
    "ensemble_coordinator = load_model('ensemble_coordinator.h5')\n",
    "\n",
    "with open('truth_predictor.pkl', 'rb') as f:\n",
    "    truth_predictor = pickle.load(f)\n",
    "    \n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "    \n",
    "with open('model_metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "def predict_single_news(title, content):\n",
    "    \"\"\"Predict if a single news article is real or fake\"\"\"\n",
    "    # Combine title and content as done during training\n",
    "    full_text = f\"{title} {content}\"\n",
    "    \n",
    "    # Preprocess the text\n",
    "    seq = tokenizer.texts_to_sequences([full_text])\n",
    "    padded = pad_sequences(seq, maxlen=metadata['max_len'])\n",
    "    \n",
    "    # Get features from News Characterizer\n",
    "    features = news_characterizer.predict(padded, verbose=0)\n",
    "    \n",
    "    # Get predictions from both components\n",
    "    coord_score = ensemble_coordinator.predict(features, verbose=0)[0][0]\n",
    "    truth_score = truth_predictor.predict(features)[0]\n",
    "    \n",
    "    # Combine predictions (average)\n",
    "    combined_score = (coord_score + truth_score) / 2\n",
    "    is_real = combined_score > 0.5\n",
    "    \n",
    "    return {\n",
    "        'title': title,\n",
    "        'content': content,\n",
    "        'prediction': 'REAL' if is_real else 'FAKE',\n",
    "        'confidence': f\"{max(combined_score, 1-combined_score)*100:.1f}%\",\n",
    "        'coordinator_score': f\"{coord_score:.4f}\",\n",
    "        'truth_predictor_score': f\"{truth_score:.4f}\",\n",
    "        'combined_score': f\"{combined_score:.4f}\",\n",
    "        'actual_label': 'REAL' if int(0) == 1 else 'FAKE'  # Since your input has label=0\n",
    "    }\n",
    "\n",
    "# Your specific input\n",
    "input_title = \"Tech Company Launches New Product\"\n",
    "input_content = \"Clickbait! No credible sources support this claim.\"\n",
    "input_label = 0  # From your dataset\n",
    "\n",
    "# Make prediction\n",
    "result = predict_single_news(input_title, input_content)\n",
    "\n",
    "# Print detailed results\n",
    "print(\"Fake News Detection Analysis:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Title: {result['title']}\")\n",
    "print(f\"Content: {result['content']}\")\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(f\"- Model Prediction: {result['prediction']} (Actual: {result['actual_label']})\")\n",
    "print(f\"- Confidence: {result['confidence']}\")\n",
    "print(\"\\nComponent Scores:\")\n",
    "print(f\"- Ensemble Coordinator: {result['coordinator_score']}\")\n",
    "print(f\"- Truth Predictor: {result['truth_predictor_score']}\")\n",
    "print(f\"- Combined Decision Score: {result['combined_score']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if prediction matches actual label\n",
    "if (result['prediction'] == 'FAKE' and input_label == 0) or (result['prediction'] == 'REAL' and input_label == 1):\n",
    "    print(\"\\n‚úÖ Prediction MATCHES the actual label!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Prediction DOES NOT match the actual label!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efafa33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake News Detection Analysis:\n",
      "======================================================================\n",
      "Title: Tech Company Launches New Product\n",
      "Content: Experts discuss the implications of the new product.\n",
      "\n",
      "Prediction Results:\n",
      "- Model Prediction: REAL (Actual: FAKE)\n",
      "- Confidence: 99.2%\n",
      "\n",
      "Component Scores:\n",
      "- Ensemble Coordinator: 0.9861\n",
      "- Truth Predictor: 0.9983\n",
      "- Combined Decision Score: 0.9922\n",
      "======================================================================\n",
      "\n",
      "‚ùå Prediction DOES NOT match the actual label!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load all model components\n",
    "news_characterizer = load_model('news_characterizer.h5')\n",
    "ensemble_coordinator = load_model('ensemble_coordinator.h5')\n",
    "\n",
    "with open('truth_predictor.pkl', 'rb') as f:\n",
    "    truth_predictor = pickle.load(f)\n",
    "    \n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "    \n",
    "with open('model_metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "def predict_single_news(title, content):\n",
    "    \"\"\"Predict if a single news article is real or fake\"\"\"\n",
    "    # Combine title and content as done during training\n",
    "    full_text = f\"{title} {content}\"\n",
    "    \n",
    "    # Preprocess the text\n",
    "    seq = tokenizer.texts_to_sequences([full_text])\n",
    "    padded = pad_sequences(seq, maxlen=metadata['max_len'])\n",
    "    \n",
    "    # Get features from News Characterizer\n",
    "    features = news_characterizer.predict(padded, verbose=0)\n",
    "    \n",
    "    # Get predictions from both components\n",
    "    coord_score = ensemble_coordinator.predict(features, verbose=0)[0][0]\n",
    "    truth_score = truth_predictor.predict(features)[0]\n",
    "    \n",
    "    # Combine predictions (average)\n",
    "    combined_score = (coord_score + truth_score) / 2\n",
    "    is_real = combined_score > 0.5\n",
    "    \n",
    "    return {\n",
    "        'title': title,\n",
    "        'content': content,\n",
    "        'prediction': 'REAL' if is_real else 'FAKE',\n",
    "        'confidence': f\"{max(combined_score, 1-combined_score)*100:.1f}%\",\n",
    "        'coordinator_score': f\"{coord_score:.4f}\",\n",
    "        'truth_predictor_score': f\"{truth_score:.4f}\",\n",
    "        'combined_score': f\"{combined_score:.4f}\",\n",
    "        'actual_label': 'REAL' if int(0) == 1 else 'FAKE'  # Since your input has label=0\n",
    "    }\n",
    "\n",
    "# Your specific input\n",
    "input_title = \"Tech Company Launches New Product\"\n",
    "input_content = \"Experts discuss the implications of the new product.\"\n",
    "input_label = 0  # From your dataset\n",
    "\n",
    "# Make prediction\n",
    "result = predict_single_news(input_title, input_content)\n",
    "\n",
    "# Print detailed results\n",
    "print(\"Fake News Detection Analysis:\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Title: {result['title']}\")\n",
    "print(f\"Content: {result['content']}\")\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(f\"- Model Prediction: {result['prediction']} (Actual: {result['actual_label']})\")\n",
    "print(f\"- Confidence: {result['confidence']}\")\n",
    "print(\"\\nComponent Scores:\")\n",
    "print(f\"- Ensemble Coordinator: {result['coordinator_score']}\")\n",
    "print(f\"- Truth Predictor: {result['truth_predictor_score']}\")\n",
    "print(f\"- Combined Decision Score: {result['combined_score']}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check if prediction matches actual label\n",
    "if (result['prediction'] == 'FAKE' and input_label == 0) or (result['prediction'] == 'REAL' and input_label == 1):\n",
    "    print(\"\\n‚úÖ Prediction MATCHES the actual label!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Prediction DOES NOT match the actual label!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e41a52c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Fake News Detection Report\n",
      "============================================================\n",
      "Title: Political Scandal Unveiled\n",
      "Content: Misinformation spreading for political gains.\n",
      "\n",
      "Final Verdict: FAKE (Confidence: 99.7%)\n",
      "Combined Score: 0.0025\n",
      "\n",
      "Component Scores:\n",
      "- Ensemble Coordinator: 0.0049\n",
      "- Truth Predictor: 0.0002\n",
      "\n",
      "Detected Keywords:\n",
      "- Clickbait: ‚ùå\n",
      "- No_sources: ‚ùå\n",
      "- Misinformation: ‚úÖ\n",
      "- Political: ‚úÖ\n",
      "============================================================\n",
      "\n",
      "Analysis: This article was classified as FAKE because:\n",
      "- Contains the term 'misinformation' which is common in fake news\n",
      "- Mentions political context, which often appears in fabricated stories\n",
      "- Extremely low confidence score indicates strong fake news signals\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load all model components\n",
    "news_characterizer = load_model('news_characterizer.h5')\n",
    "ensemble_coordinator = load_model('ensemble_coordinator.h5')\n",
    "\n",
    "with open('truth_predictor.pkl', 'rb') as f:\n",
    "    truth_predictor = pickle.load(f)\n",
    "    \n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "    \n",
    "with open('model_metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "def predict_news(title, content):\n",
    "    \"\"\"Predict if a news article is real or fake with detailed analysis\"\"\"\n",
    "    # Combine title and content\n",
    "    full_text = f\"{title} {content}\"\n",
    "    \n",
    "    # Preprocess the text\n",
    "    seq = tokenizer.texts_to_sequences([full_text])\n",
    "    padded = pad_sequences(seq, maxlen=metadata['max_len'])\n",
    "    \n",
    "    # Get features from News Characterizer\n",
    "    features = news_characterizer.predict(padded, verbose=0)\n",
    "    \n",
    "    # Get predictions from both components\n",
    "    coord_score = ensemble_coordinator.predict(features, verbose=0)[0][0]\n",
    "    truth_score = truth_predictor.predict(features)[0]\n",
    "    \n",
    "    # Combine predictions\n",
    "    combined_score = (coord_score + truth_score) / 2\n",
    "    is_real = combined_score > 0.5\n",
    "    \n",
    "    # Calculate confidence percentage\n",
    "    confidence = max(combined_score, 1-combined_score)*100\n",
    "    \n",
    "    return {\n",
    "        'title': title,\n",
    "        'content': content,\n",
    "        'prediction': 'REAL' if is_real else 'FAKE',\n",
    "        'confidence': f\"{confidence:.1f}%\",\n",
    "        'coordinator_score': coord_score,\n",
    "        'truth_predictor_score': truth_score,\n",
    "        'combined_score': combined_score,\n",
    "        'keywords': {\n",
    "            'clickbait': 'Clickbait!' in content,\n",
    "            'no_sources': 'no credible sources' in content.lower(),\n",
    "            'misinformation': 'misinformation' in content.lower(),\n",
    "            'political': 'political' in content.lower()\n",
    "        }\n",
    "    }\n",
    "\n",
    "# The news article to analyze\n",
    "news_title = \"Political Scandal Unveiled\"  # Example title\n",
    "news_content = \"Misinformation spreading for political gains.\"\n",
    "\n",
    "# Make prediction\n",
    "result = predict_news(news_title, news_content)\n",
    "\n",
    "# Print results with analysis\n",
    "print(\"üîç Fake News Detection Report\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Title: {result['title']}\")\n",
    "print(f\"Content: {result['content']}\\n\")\n",
    "print(f\"Final Verdict: {result['prediction']} (Confidence: {result['confidence']})\")\n",
    "print(f\"Combined Score: {result['combined_score']:.4f}\\n\")\n",
    "\n",
    "print(\"Component Scores:\")\n",
    "print(f\"- Ensemble Coordinator: {result['coordinator_score']:.4f}\")\n",
    "print(f\"- Truth Predictor: {result['truth_predictor_score']:.4f}\\n\")\n",
    "\n",
    "print(\"Detected Keywords:\")\n",
    "for kw, detected in result['keywords'].items():\n",
    "    print(f\"- {kw.capitalize()}: {'‚úÖ' if detected else '‚ùå'}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Interpretation\n",
    "if result['prediction'] == 'FAKE':\n",
    "    print(\"\\nAnalysis: This article was classified as FAKE because:\")\n",
    "    if result['keywords']['misinformation']:\n",
    "        print(\"- Contains the term 'misinformation' which is common in fake news\")\n",
    "    if result['keywords']['political']:\n",
    "        print(\"- Mentions political context, which often appears in fabricated stories\")\n",
    "    if result['combined_score'] < 0.3:\n",
    "        print(\"- Extremely low confidence score indicates strong fake news signals\")\n",
    "else:\n",
    "    print(\"\\nAnalysis: This article was classified as REAL because:\")\n",
    "    print(\"- The content lacks common fake news indicators\")\n",
    "    print(\"- Scores from both components agree on its authenticity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7acaa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∞ News Authenticity Report\n",
      "============================================================\n",
      "Title: Government Announces New Policy\n",
      "Content: The government released an official statement.\n",
      "\n",
      "Prediction: REAL news\n",
      "Confidence: 87.2%\n",
      "Combined Score: 0.8723\n",
      "\n",
      "Component Scores:\n",
      "- Ensemble Coordinator: 0.9124\n",
      "- Truth Predictor: 0.8322\n",
      "\n",
      "Key Indicators:\n",
      "- ‚úÖ official statement\n",
      "- ‚úÖ government source\n",
      "- ‚ùå negative phrases\n",
      "============================================================\n",
      "\n",
      "Analysis: This article was classified as REAL because:\n",
      "- Contains reference to an official government statement\n",
      "- No negative phrases suggesting fabrication\n",
      "- Both model components agreed on authenticity\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load all model components\n",
    "news_characterizer = load_model('news_characterizer.h5')\n",
    "ensemble_coordinator = load_model('ensemble_coordinator.h5')\n",
    "\n",
    "with open('truth_predictor.pkl', 'rb') as f:\n",
    "    truth_predictor = pickle.load(f)\n",
    "    \n",
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "    \n",
    "with open('model_metadata.pkl', 'rb') as f:\n",
    "    metadata = pickle.load(f)\n",
    "\n",
    "def predict_news(title, content):\n",
    "    \"\"\"Predict if a news article is real or fake with detailed analysis\"\"\"\n",
    "    # Combine title and content\n",
    "    full_text = f\"{title} {content}\"\n",
    "    \n",
    "    # Preprocess the text\n",
    "    seq = tokenizer.texts_to_sequences([full_text])\n",
    "    padded = pad_sequences(seq, maxlen=metadata['max_len'])\n",
    "    \n",
    "    # Get features from News Characterizer\n",
    "    features = news_characterizer.predict(padded, verbose=0)\n",
    "    \n",
    "    # Get predictions from both components\n",
    "    coord_score = ensemble_coordinator.predict(features, verbose=0)[0][0]\n",
    "    truth_score = truth_predictor.predict(features)[0]\n",
    "    \n",
    "    # Combine predictions\n",
    "    combined_score = (coord_score + truth_score) / 2\n",
    "    is_real = combined_score > 0.5\n",
    "    \n",
    "    return {\n",
    "        'title': title,\n",
    "        'content': content,\n",
    "        'prediction': 'REAL' if is_real else 'FAKE',\n",
    "        'confidence': f\"{max(combined_score, 1-combined_score)*100:.1f}%\",\n",
    "        'coordinator_score': f\"{coord_score:.4f}\",\n",
    "        'truth_predictor_score': f\"{truth_score:.4f}\",\n",
    "        'combined_score': f\"{combined_score:.4f}\",\n",
    "        'indicators': {\n",
    "            'official_statement': 'official statement' in content.lower(),\n",
    "            'government_source': 'government' in content.lower(),\n",
    "            'negative_phrases': any(phrase in content.lower() for phrase in ['fake', 'fabricated', 'misinformation'])\n",
    "        }\n",
    "    }\n",
    "\n",
    "# The news article to analyze\n",
    "news_title = \"Government Announces New Policy\"\n",
    "news_content = \"The government released an official statement.\"\n",
    "\n",
    "# Make prediction\n",
    "result = predict_news(news_title, news_content)\n",
    "\n",
    "# Print results\n",
    "print(\"üì∞ News Authenticity Report\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Title: {result['title']}\")\n",
    "print(f\"Content: {result['content']}\\n\")\n",
    "print(f\"Prediction: {result['prediction']} news\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n",
    "print(f\"Combined Score: {result['combined_score']}\\n\")\n",
    "\n",
    "print(\"Component Scores:\")\n",
    "print(f\"- Ensemble Coordinator: {result['coordinator_score']}\")\n",
    "print(f\"- Truth Predictor: {result['truth_predictor_score']}\\n\")\n",
    "\n",
    "print(\"Key Indicators:\")\n",
    "for indicator, present in result['indicators'].items():\n",
    "    print(f\"- {'‚úÖ' if present else '‚ùå'} {indicator.replace('_', ' ')}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Explanation\n",
    "if result['prediction'] == 'REAL':\n",
    "    print(\"\\nAnalysis: This article was classified as REAL because:\")\n",
    "    print(\"- Contains reference to an official government statement\")\n",
    "    print(\"- No negative phrases suggesting fabrication\")\n",
    "    print(\"- Both model components agreed on authenticity\")\n",
    "else:\n",
    "    print(\"\\nAnalysis: This article was classified as FAKE because:\")\n",
    "    if result['indicators']['negative_phrases']:\n",
    "        print(\"- Contains phrases commonly found in fake news\")\n",
    "    if result['combined_score'] < 0.3:\n",
    "        print(\"- Extremely low confidence score indicates suspicious content\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe043ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\n",
      "Simplified FNED Performance:\n",
      "Accuracy: 0.8150\n",
      "Precision: 0.7661\n",
      "Recall: 0.9223\n",
      "F1 Score: 0.8370\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load and preprocess data\n",
    "df = pd.read_csv('D:/dataset/fake_news_dataset.csv')\n",
    "df['text'] = df['Article Title'] + ' ' + df['Content']\n",
    "X = df['text']\n",
    "y = df['Label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization\n",
    "max_words = 8000\n",
    "max_len = 150\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Simple News Characterizer (CNN)\n",
    "def build_simple_characterizer():\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=64)(input_layer)\n",
    "    conv = Conv1D(filters=32, kernel_size=5, activation='relu')(embedding)\n",
    "    pool = GlobalMaxPooling1D()(conv)\n",
    "    output = Dense(64, activation='relu')(pool)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Truth Predictor: Logistic Regression\n",
    "class SimpleTruthPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Build and train FNED model\n",
    "characterizer = build_simple_characterizer()\n",
    "\n",
    "# Extract features\n",
    "X_train_features = characterizer.predict(X_train_pad)\n",
    "X_test_features = characterizer.predict(X_test_pad)\n",
    "\n",
    "# Train truth predictor\n",
    "truth_predictor = SimpleTruthPredictor()\n",
    "truth_predictor.fit(X_train_features, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "probs = truth_predictor.predict(X_test_features)\n",
    "preds = (probs > 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "precision = precision_score(y_test, preds)\n",
    "recall = recall_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds)\n",
    "\n",
    "print(\"\\nSimplified FNED Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1205d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "\n",
      "üì∞ News Authenticity Report\n",
      "============================================================\n",
      "Accuracy : 0.6950\n",
      "Precision: 0.6419\n",
      "Recall   : 0.9223\n",
      "F1 Score : 0.7570\n"
     ]
    }
   ],
   "source": [
    "#real\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('D:/dataset/fake_news_dataset.csv')\n",
    "df['text'] = df['Article Title'] + ' ' + df['Content']\n",
    "X = df['text']\n",
    "y = df['Label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization\n",
    "max_words = 8000\n",
    "max_len = 150\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Define News Characterizer (CNN)\n",
    "def build_characterizer():\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=64)(input_layer)\n",
    "    conv = Conv1D(filters=32, kernel_size=5, activation='relu')(embedding)\n",
    "    pool = GlobalMaxPooling1D()(conv)\n",
    "    output = Dense(64, activation='relu')(pool)\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Truth Predictor\n",
    "class TruthPredictor:\n",
    "    def __init__(self):\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict_proba(X)[:, 1]\n",
    "\n",
    "# Build and train model\n",
    "characterizer = build_characterizer()\n",
    "\n",
    "# Compile manually if needed (in case you use .h5 model in future)\n",
    "characterizer.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Feature extraction\n",
    "X_train_feat = characterizer.predict(X_train_pad)\n",
    "X_test_feat = characterizer.predict(X_test_pad)\n",
    "\n",
    "# Train and predict\n",
    "truth_predictor = TruthPredictor()\n",
    "truth_predictor.fit(X_train_feat, y_train)\n",
    "probs = truth_predictor.predict(X_test_feat)\n",
    "final_preds = (probs > 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, final_preds)\n",
    "precision = precision_score(y_test, final_preds)\n",
    "recall = recall_score(y_test, final_preds)\n",
    "f1 = f1_score(y_test, final_preds)\n",
    "\n",
    "# Output\n",
    "print(\"\\nüì∞ News Authenticity Report\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99dc8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∞ News Authenticity Report\n",
      "============================================================\n",
      "Accuracy : 1.0000\n",
      "Precision: 1.0000\n",
      "Recall   : 1.0000\n",
      "F1 Score : 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('D:/dataset/fake_news_dataset.csv')\n",
    "df['text'] = df['Article Title'] + ' ' + df['Content']\n",
    "X = df['text']\n",
    "y = df['Label']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 250\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Improved CNN Feature Extractor\n",
    "def build_characterizer():\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=128)(input_layer)\n",
    "    \n",
    "    conv3 = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding)\n",
    "    pool3 = GlobalMaxPooling1D()(conv3)\n",
    "    \n",
    "    conv5 = Conv1D(filters=64, kernel_size=5, activation='relu')(embedding)\n",
    "    pool5 = GlobalMaxPooling1D()(conv5)\n",
    "    \n",
    "    conv7 = Conv1D(filters=64, kernel_size=7, activation='relu')(embedding)\n",
    "    pool7 = GlobalMaxPooling1D()(conv7)\n",
    "    \n",
    "    merged = concatenate([pool3, pool5, pool7])\n",
    "    dropout = Dropout(0.5)(merged)\n",
    "    output = Dense(128, activation='relu')(dropout)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Truth Predictor with scaling\n",
    "class TruthPredictor:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.model.fit(X_scaled, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "# Train pipeline\n",
    "characterizer = build_characterizer()\n",
    "characterizer.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Feature extraction\n",
    "X_train_feat = characterizer.predict(X_train_pad, verbose=0)\n",
    "X_test_feat = characterizer.predict(X_test_pad, verbose=0)\n",
    "\n",
    "# Train and predict\n",
    "truth_predictor = TruthPredictor()\n",
    "truth_predictor.fit(X_train_feat, y_train)\n",
    "probs = truth_predictor.predict(X_test_feat)\n",
    "final_preds = (probs > 0.5).astype(int)\n",
    "\n",
    "# Evaluation\n",
    "accuracy = accuracy_score(y_test, final_preds)\n",
    "precision = precision_score(y_test, final_preds)\n",
    "recall = recall_score(y_test, final_preds)\n",
    "f1 = f1_score(y_test, final_preds)\n",
    "\n",
    "# Output\n",
    "print(\"\\nüì∞ News Authenticity Report\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a27a4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, TFBertModel\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msequence\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Suppress TensorFlow warnings\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "# from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from transformers import BertTokenizer, TFBertModel\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# # Load dataset\n",
    "# df = pd.read_csv('D:/dataset/fake_news_dataset.csv')\n",
    "# df['text'] = df['Article Title'] + ' ' + df['Content']\n",
    "# X = df['text']\n",
    "# y = df['Label']\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Load BERT tokenizer and model\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# # Tokenization (BERT-specific)\n",
    "# max_len = 512  # Max length for BERT\n",
    "# X_train_tokens = tokenizer(list(X_train), padding=True, truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
    "# X_test_tokens = tokenizer(list(X_test), padding=True, truncation=True, max_length=max_len, return_tensors=\"tf\")\n",
    "\n",
    "# # BERT Model for Feature Extraction\n",
    "# def build_bert_model():\n",
    "#     input_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32)\n",
    "#     attention_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32)\n",
    "\n",
    "#     bert_output = bert_model(input_ids, attention_mask=attention_mask)[1]  # [1] is pooled output\n",
    "#     output = tf.keras.layers.Dense(128, activation='relu')(bert_output)\n",
    "#     output = tf.keras.layers.Dense(1, activation='sigmoid')(output)  # Binary classification\n",
    "#     model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "\n",
    "#     model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "# # Initialize and train the BERT model\n",
    "# print(\"üîß Building and training BERT model...\")\n",
    "# bert_model = build_bert_model()\n",
    "\n",
    "# # Train the model\n",
    "# bert_model.fit(\n",
    "#     [X_train_tokens['input_ids'], X_train_tokens['attention_mask']], \n",
    "#     y_train, \n",
    "#     epochs=3, \n",
    "#     batch_size=8, \n",
    "#     validation_split=0.1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# # Feature extraction from BERT model\n",
    "# train_features = bert_model.predict([X_train_tokens['input_ids'], X_train_tokens['attention_mask']])\n",
    "# test_features = bert_model.predict([X_test_tokens['input_ids'], X_test_tokens['attention_mask']])\n",
    "\n",
    "# # Ensemble classifier (Voting Classifier with Random Forest + SVM)\n",
    "# print(\"üß† Training Voting Classifier...\")\n",
    "# ensemble_model = VotingClassifier(\n",
    "#     estimators=[\n",
    "#         ('rf', RandomForestClassifier(n_estimators=100)),\n",
    "#         ('svc', SVC(probability=True))\n",
    "#     ], voting='soft'\n",
    "# )\n",
    "\n",
    "# ensemble_model.fit(train_features, y_train)\n",
    "\n",
    "# # Predictions\n",
    "# print(\"üîé Making predictions...\")\n",
    "# final_preds = ensemble_model.predict(test_features)\n",
    "\n",
    "# # Evaluate\n",
    "# accuracy = accuracy_score(y_test, final_preds)\n",
    "# precision = precision_score(y_test, final_preds)\n",
    "# recall = recall_score(y_test, final_preds)\n",
    "# f1 = f1_score(y_test, final_preds)\n",
    "\n",
    "# # Print results\n",
    "# print(\"\\nüì∞ News Authenticity Report\")\n",
    "# print(\"=\" * 60)\n",
    "# print(f\"Accuracy : {accuracy:.4f}\")\n",
    "# print(f\"Precision: {precision:.4f}\")\n",
    "# print(f\"Recall   : {recall:.4f}\")\n",
    "# print(f\"F1 Score : {f1:.4f}\")\n",
    "\n",
    "# # Confusion Matrix\n",
    "# conf_matrix = confusion_matrix(y_test, final_preds)\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])\n",
    "# plt.xlabel('Predicted')\n",
    "# plt.ylabel('True')\n",
    "# plt.title('Confusion Matrix')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c36f1870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì∞ News Authenticity Report\n",
      "============================================================\n",
      "Accuracy : 1.0000\n",
      "Precision: 1.0000\n",
      "Recall   : 1.0000\n",
      "F1 Score : 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, concatenate, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load and preprocess dataset\n",
    "df = pd.read_csv('D:/dataset/fake_news_dataset.csv')\n",
    "df['text'] = df['Article Title'] + ' ' + df['Content']\n",
    "X = df['text']\n",
    "y = df['Label']\n",
    "\n",
    "# Split data with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Tokenization\n",
    "max_words = 10000\n",
    "max_len = 250\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# CNN Feature Extractor\n",
    "def build_characterizer():\n",
    "    input_layer = Input(shape=(max_len,))\n",
    "    embedding = Embedding(input_dim=max_words, output_dim=128)(input_layer)\n",
    "    embedding = Dropout(0.3)(embedding)  # Extra regularization\n",
    "\n",
    "    conv3 = Conv1D(filters=64, kernel_size=3, activation='relu')(embedding)\n",
    "    pool3 = GlobalMaxPooling1D()(conv3)\n",
    "\n",
    "    conv5 = Conv1D(filters=64, kernel_size=5, activation='relu')(embedding)\n",
    "    pool5 = GlobalMaxPooling1D()(conv5)\n",
    "\n",
    "    conv7 = Conv1D(filters=64, kernel_size=7, activation='relu')(embedding)\n",
    "    pool7 = GlobalMaxPooling1D()(conv7)\n",
    "\n",
    "    merged = concatenate([pool3, pool5, pool7])\n",
    "    dropout = Dropout(0.5)(merged)\n",
    "    output = Dense(128, activation='relu')(dropout)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# Logistic Regression classifier\n",
    "class TruthPredictor:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = LogisticRegression(max_iter=1000)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        self.model.fit(X_scaled, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_scaled = self.scaler.transform(X)\n",
    "        return self.model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "# Build model and extract features\n",
    "characterizer = build_characterizer()\n",
    "characterizer.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "X_train_feat = characterizer.predict(X_train_pad, verbose=0)\n",
    "X_test_feat = characterizer.predict(X_test_pad, verbose=0)\n",
    "\n",
    "# Train and evaluate\n",
    "truth_predictor = TruthPredictor()\n",
    "truth_predictor.fit(X_train_feat, y_train)\n",
    "probs = truth_predictor.predict(X_test_feat)\n",
    "final_preds = (probs > 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "accuracy = accuracy_score(y_test, final_preds)\n",
    "precision = precision_score(y_test, final_preds)\n",
    "recall = recall_score(y_test, final_preds)\n",
    "f1 = f1_score(y_test, final_preds)\n",
    "\n",
    "# Output\n",
    "print(\"\\nüì∞ News Authenticity Report\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
